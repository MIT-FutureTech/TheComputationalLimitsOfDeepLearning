name,year,parameters,title,paper_with_code,paper_link,flops,multiadds,fp_bp_ratio,training_epochs,training_set_size,training_dataset,training_time_total,training_time_total_sec,training_time_tpu_core_days,training_gpu_model,training_gpu_amount,training_gpu_ptp_gflops,training_tpu_model,training_tpu_amount,training_tpu_ptp_gflops,training_cpu_model,training_cpu_amount,training_cpu_ptp_gflops,pretraining_epochs,pretraining_set_size,pretraining_dataset,pretraining_time_total,pretraining_time_total_sec,pretraining_time_tpu_core_days,pretraining_gpu_model,pretraining_gpu_amount,pretraining_gpu_ptp_gflops,pretraining_tpu_model,pretraining_tpu_amount,pretraining_tpu_ptp_gflops,pretraining_cpu_model,pretraining_cpu_amount,pretraining_cpu_ptp_gflops,finetuning_epochs,finetuning_set_size,finetuning_dataset,finetuning_time_total,finetuning_time_total_sec,finetuning_time_tpu_core_days,finetuning_gpu_model,finetuning_gpu_amount,finetuning_gpu_ptp_gflops,finetuning_tpu_model,finetuning_tpu_amount,finetuning_tpu_ptp_gflops,finetuning_cpu_model,finetuning_cpu_amount,finetuning_cpu_ptp_gflops,network_operations,hardware_burden,log10net,log10hw,computing_power,comments,relevant,(TOP 1 score),(TOP 5 score)
name,year,parameters,paper,,,ops_forward_pass,,fp_bp_ratio,training,,,,,,,,,,,,,,,pre_training,,,,,,,,,,,,,,,fine_tuning,,,,,,,,,,,,,,,net_ops,hw_burden,log10(net_ops),log10(hw_bruden),,comments,,performance_metrics,
,,,title,pwc_url,paper_url,flops,multiadds,,epochs,set_size,dataset_name,time,,,gpu,,,tpu,,,cpu,,,epochs,set_size,dataset_name,time,,,gpu,,,tpu,,,cpu,,,epochs,set_size,dataset_name,time,,,gpu,,,tpu,,,cpu,,,,,,,hw_burden_consolidated,,,top1_score,top5_score
,,,,,,,,,,,,total,total_sec, tpu_core_days,model,amount,ptp_gflops,model,amount,ptp_gflops,model,amount,ptp_gflops,,,,total,total_sec, tpu_core_days,model,amount,ptp_gflops,model,amount,ptp_gflops,model,amount,ptp_gflops,,,,total,total_sec, tpu_core_days,model,amount,ptp_flops,model,amount,ptp_gflops,model,amount,ptp_gflops,,,,,,,relevant,,
CoCa,2022,,CoCa: Contrastive Captioners are Image-Text Foundation Models,/paper/coca-contrastive-captioners-are-image-text,https://arxiv.org/pdf/2205.01917v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,5 days,4.32E+05,,,,,Cloud TPU v4,512,1.10E+06,,,,,,,,,,,,,,,,,,,,2.4E+23,,23.38614639,2.4E+23,,,91.00,
Model soups (ViT-G/14),2022,,Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time,/paper/model-soups-averaging-weights-of-multiple,https://arxiv.org/pdf/2203.05482v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.94,
ViT-G/14,2021,1.84E+09,Scaling Vision Transformers,/paper/scaling-vision-transformers,https://arxiv.org/abs/2106.04560v1,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,Cloud TPU v3,256,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,90.45,
ViT-MoE-15B (Every-2),2021,1.47E+10,Scaling Vision with Sparse Mixture of Experts,/paper/scaling-vision-with-sparse-mixture-of-experts,https://arxiv.org/abs/2106.05974v1,,,3,,1280000,ImageNet 1K,16775.5 days,1.45E+09,1.68E+04,,,,Cloud TPU v3,0.125,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.39E+22,7.6E+22,22.5301997,22.88134852,7.6E+22,,,90.35,
Meta Pseudo Labels (EfficientNet-L2),2020,4.80E+08,Meta Pseudo Labels,/paper/meta-pseudo-labels,http://openaccess.thecvf.com//content/CVPR2021/html/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.html,,,3,,1280000,ImageNet 1K,11 days,9.50E+05,,,,,Cloud TPU v3,256,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0E+23,,23.00939568,1.0E+23,,,90.20,98.8
SwinV2-G,2021,3.00E+09,Swin Transformer V2: Scaling Up Capacity and Resolution,/paper/swin-transformer-v2-scaling-up-capacity-and,https://arxiv.org/pdf/2111.09883v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,5.00E+02,,,,Cloud TPU v3,,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,90.17,
Florence-CoSwin-H,2021,,Florence: A New Foundation Model for Computer Vision,/paper/florence-a-new-foundation-model-for-computer,https://arxiv.org/pdf/2111.11432v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,90.05,99.02
TokenLearner L/8 (24+11),2021,4.60E+08,TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?,/paper/tokenlearner-what-can-8-learned-tokens-do-for,https://arxiv.org/pdf/2106.11297v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.87,
ALIGN (EfficientNet-L2),2021,4.80E+08,Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision,/paper/scaling-up-visual-and-vision-language,https://arxiv.org/abs/2102.05918v2,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,128,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.64,98.67
EfficientNet-L2-475 (SAM),2020,4.80E+08,Sharpness-Aware Minimization for Efficiently Improving Generalization,/paper/sharpness-aware-minimization-for-efficiently-1,https://openreview.net/forum?id=6Tm1mposlrM,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.61,
CoAtNet-4 + PT-RA-E150 ,2021,2.44E+09,CoAtNet: Marrying Convolution and Attention for All Data Sizes,/paper/coatnet-marrying-convolution-and-attention,https://arxiv.org/pdf/2106.04803v2.pdf,3.61E+11,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,,4.20E+05,,,,150,14200000,ImageNet 22K,,,9.50E+02,,,,Cloud TPU v3,,,,,,30,1280000,ImageNet 1K,,,,,,,,,,,,,2.35E+21,,21.37064754,,5.7E+21,,,88.56,
ViT-H/14,2020,,An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,/paper/an-image-is-worth-16x16-words-transformers-1,https://arxiv.org/pdf/2010.11929v2.pdf,,,3,,1280000,ImageNet 1K,312.5 days,2.70E+07,2.50E+03,,,,Cloud TPU v3,1,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.1E+22,,22.05461305,1.1E+22,,,88.55,
FixEfficientNet-L2,2020,4.80E+08,Fixing the train-test resolution discrepancy: FixEfficientNet,/paper/fixing-the-train-test-resolution-discrepancy-2,https://arxiv.org/abs/2003.08237v5,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,88.50,98.7
NoisyStudent (EfficientNet-L2),2020,4.80E+08,Self-training with Noisy Student improves ImageNet classification,/paper/self-training-with-noisy-student-improves,https://arxiv.org/abs/1911.04252,,,3,,1280000,ImageNet 1K,6 days,5.18E+05,,,,,Cloud TPU v3,256,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.6E+22,,22.74615425,5.6E+22,,,88.40,98.7
Mixer-H/14 (JFT-300M pre-train),2021,,MLP-Mixer: An all-MLP Architecture for Vision,/paper/mlp-mixer-an-all-mlp-architecture-for-vision,https://arxiv.org/abs/2105.01601v4,,,3,,1280000,ImageNet 1K,,,1.01E+03,,,,Cloud TPU v3,,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.94,
ConvNeXt-XL,2022,3.50E+08,A ConvNet for the 2020s,/paper/a-convnet-for-the-2020s,https://arxiv.org/pdf/2201.03545v1.pdf,1.79E+11,,3,300,1280000,ImageNet 1K,9.13E+20,,,,,,,,,,,,90,14200000,ImageNet 22K,,,,,,,,,,,,,30,1280000,ImageNet 1K,,,,,,,,,,,,,9.13E+20,,20.96052538,,2.5E+21,,,87.80,
VIT-H448 (MAE),2021,,Masked Autoencoders Are Scalable Vision Learners,/paper/masked-autoencoders-are-scalable-vision,https://arxiv.org/pdf/2111.06377v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,16,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.80,
"CvT-W24 (384 res, ImageNet-22k pretrain)",2021,2.77E+08,CvT: Introducing Convolutions to Vision Transformers,/paper/cvt-introducing-convolutions-to-vision,https://arxiv.org/abs/2103.15808v1,1.93E+11,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.22E+20,,20.34700979,,7.3E+20,,,87.70,
BiT-L (ResNet),2021,,Big Transfer (BiT): General Visual Representation Learning,/paper/large-scale-learning-of-general-visual,https://arxiv.org/pdf/1912.11370v3.pdf,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,64,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,87.54,98.46
"CSWin-L (384 res,ImageNet-22k pretrain)",2022,1.73E+08,CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows,/paper/cswin-transformer-a-general-vision,https://arxiv.org/pdf/2107.00652.pdf,9.68E+10,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,90,14200000,ImageNet 22K,,,,,,,,,,,,,30,1280000,ImageNet 1K,,,,,,,,,,,,,1.30221E+20,,20.11468223,,4.6E+20,pretrained on 14M images (Imagenet-21k) for 90 epochs at 224x224 resolution (31.5GFLOPS/image) + fine-tuned on Imagenet-1k (1.28M images at 338x338 res) with 96.8GFLOPS per image,,87.50,
"Swin-L (384 res, ImageNet-22k pretrain)",2021,1.97E+08,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,/paper/swin-transformer-hierarchical-vision,https://arxiv.org/abs/2103.14030v1,1.04E+11,,3,320,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,60,14200000,ImageNet 22K,,,,,,,,,,,,,3.94E+20,,20.59507627,,1.2E+21,,,87.30,
EfficientNetV2-XL (21k),2021,1.21E+08,EfficientNetV2: Smaller Models and Faster Training,/paper/efficientnetv2-smaller-models-and-faster,https://arxiv.org/abs/2104.00298v3,9.40E+10,,3,60,14200000,ImageNet 21K,45 hours,1.62E+05,,,,,Cloud TPU v3,4,4.20E+05,,,,,,,,,,,,,,,,,,,15,1280000,ImageNet 1K,,,,,,,,,,,,,2.46E+20,2.7E+20,20.39036698,20.4348243,2.7E+20,,,87.30,
VOLO-D5,2021,2.96E+08,VOLO: Vision Outlooker for Visual Recognition,/paper/volo-vision-outlooker-for-visual-recognition,https://arxiv.org/abs/2106.13112v2,4.12E+11,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.75E+20,,20.6763497,,1.4E+21,,,87.10,
NFNet-F5 w/ SAM w/ augmult=16,2021,3.77E+08,Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error,/paper/drawing-multiple-augmentation-samples-per,https://arxiv.org/pdf/2105.13343.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86.78,
NFNet-F6+SAM,2021,4.38E+08,High-Performance Large-Scale Image Recognition Without Normalization,/paper/high-performance-large-scale-image,https://arxiv.org/abs/2102.06171v1,3.77E+11,,3,360,1280000,ImageNet 1K,7.265625 days,6.28E+05,1.86E+03,,,,Cloud TPU v3,32,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.21E+20,8.4E+21,20.71697508,21.92618599,8.4E+21,,,86.50,97.9
CaiT-M-48-448,2021,3.56E+08,Going deeper with Image Transformers,/paper/going-deeper-with-image-transformers,https://arxiv.org/abs/2103.17239v2,3.29E+11,,3,400,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,1,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.05E+20,,20.70358711,,1.5E+21,,,86.50,
LV-ViT-L,2021,1.51E+08,All Tokens Matter: Token Labeling for Training Better Vision Transformers,/paper/token-labeling-training-a-85-5-top-1-accuracy,https://arxiv.org/abs/2104.10858v3,2.15E+11,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.48E+20,,20.39389094,,8.1E+20,,,86.40,
FixResNeXt-101 32x48d,2019,8.29E+08,Fixing the train-test resolution discrepancy,/paper/fixing-the-train-test-resolution-discrepancy,https://arxiv.org/pdf/1906.06423v3.pdf,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86.40,98
BEiT-B (ViT; ImageNet 1K pretrain),2021,8.60E+07,BEiT: BERT Pre-Training of Image Transformers,/paper/beit-bert-pre-training-of-image-transformers,https://arxiv.org/abs/2106.08254v1,,,3,,1280000,ImageNet 1K,5 days,4.32E+05,,Tesla V100 PCIe 32 GB,16,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.8E+19,,19.98974589,9.8E+19,,,86.30,
ViL-Base-RPB (21k),2021,5.57E+07,Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding,/paper/2103-15358,https://arxiv.org/abs/2103.15358v2,4.37E+10,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,90,14200000,ImageNet 21K,,,,,,,,,,,,,30,1280000,ImageNet 1K,,,,,,,,,,,,,1.73E+20,,20.23699057,,5.9E+20,,,86.20,
XCiT-L24,2021,1.89E+08,XCiT: Cross-Covariance Image Transformers,/paper/xcit-cross-covariance-image-transformers,https://arxiv.org/abs/2106.09681v2,,4.18E+11,3,400,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.28E+21,,21.10859749,,3.4E+21,,,86.00,
Refined-ViT-L (448),2021,8.10E+07,Refiner: Refining Self-attention for Vision Transformers,/paper/refiner-refining-self-attention-for-vision,https://arxiv.org/abs/2106.03714v1,9.80E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.13E+20,,20.05267855,,4.1E+20,,,85.90,
Fix-EfficientNet-B8 (MaxUp + CutMix),2020,8.74E+07,MaxUp: A Simple Way to Improve Generalization of Neural Network Training,/paper/maxup-a-simple-way-to-improve-generalization,https://arxiv.org/abs/2002.09024v1,1.02E+11,,3,,1280000,ImageNet 1K,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.80,
KDforAA (EfficientNet-B8),2020,8.80E+07,Circumventing Outliers of AutoAugment with Knowledge Distillation,/paper/circumventing-outliers-of-autoaugment-with,https://arxiv.org/pdf/2003.11342.pdf,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,256,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.80,
"HaloNet4 (base 128, Conv-12)",2021,8.70E+07,Scaling Local Self-Attention for Parameter Efficient Visual Backbones,/paper/scaling-local-self-attention-for-parameter,http://openaccess.thecvf.com//content/CVPR2021/html/Vaswani_Scaling_Local_Self-Attention_for_Parameter_Efficient_Visual_Backbones_CVPR_2021_paper.html,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.80,
AdvProp (EfficientNet-B8),2019,8.80E+07,Adversarial Examples Improve Image Recognition,/paper/adversarial-examples-improve-image,https://arxiv.org/pdf/1911.09665v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.50,97.3
ResNeXt-101 32x48d,2018,8.29E+08,Exploring the Limits of Weakly Supervised Pretraining,/paper/exploring-the-limits-of-weakly-supervised,https://arxiv.org/pdf/1805.00932v1.pdf,,1.53E+11,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.40,97.6
DeiT-B 384 (1000 epochs),2021,8.70E+07,Training data-efficient image transformers & distillation through attention,/paper/training-data-efficient-image-transformers,https://arxiv.org/abs/2012.12877v2,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.20,
EfficientNet-B7 (RandAugment),2019,6.60E+07,RandAugment: Practical automated data augmentation with a reduced search space,/paper/randaugment-practical-data-augmentation-with,https://arxiv.org/pdf/1909.13719v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85.00,
DAT-B,2022,8.80E+07,Vision Transformer with Deformable Attention,/paper/vision-transformer-with-deformable-attention,https://arxiv.org/pdf/2201.00520v1.pdf,4.98E+10,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.74E+19,,19.75868182,,2.3E+20,,,84.80,
MViT-B-24,2021,7.29E+07,Multiscale Vision Transformers,/paper/multiscale-vision-transformers,https://arxiv.org/pdf/2104.11227v1.pdf,3.27E+10,,3,300,1280000,ImageNet 1K,,,,,64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.77E+19,,19.57600023,,1.6E+20,,,84.80,
ResNeXt-101 32x16d (semi-weakly sup.),2019,1.93E+08,Billion-scale semi-supervised learning for image classification,/paper/billion-scale-semi-supervised-learning-for,https://arxiv.org/pdf/1905.00546v1.pdf,,,3,,1280000,ImageNet 1K,,,,,64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.80,97.4
BoTNet T7,2021,7.51E+07,Bottleneck Transformers for Visual Recognition,/paper/bottleneck-transformers-for-visual,http://openaccess.thecvf.com//content/CVPR2021/html/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.html,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,1,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.70,97
ResNeSt-269,2020,,ResNeSt: Split-Attention Networks,/paper/resnest-split-attention-networks,https://arxiv.org/abs/2004.08955v2,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.50,
ResNet-RS-420,2021,1.92E+08,Revisiting ResNets: Improved Training and Scaling Strategies,/paper/revisiting-resnets-improved-training-and,https://arxiv.org/abs/2103.07579v1,1.28E+11,,3,350,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.72E+20,,20.23560924,,5.9E+20,,,84.40,
Gpipe,2018,5.57E+08,GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism,/paper/gpipe-efficient-training-of-giant-neural,https://arxiv.org/pdf/1811.06965v5.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.40,97
DeepVit-L* (384),2021,,DeepViT: Towards Deeper Vision Transformer,/paper/deepvit-towards-deeper-vision-transformer,https://arxiv.org/abs/2103.11886v4,,1.28E+10,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.95E+19,,19.46969244,,1.3E+20,,,84.30,
EfficientNet-B7,2019,6.60E+07,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,/paper/efficientnet-rethinking-model-scaling-for,https://arxiv.org/pdf/1905.11946v5.pdf,3.70E+10,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.30,97
TResNet-XL,2020,7.70E+07,TResNet: High Performance GPU-Dedicated Architecture,/paper/tresnet-high-performance-gpu-dedicated,https://arxiv.org/abs/2003.13630v3,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.30,
LambdaResNet200,2021,4.20E+07,LambdaNetworks: Modeling Long-Range Interactions Without Attention,/paper/lambdanetworks-modeling-long-range-1,https://openreview.net/forum?id=xTJEN-ggl1b,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.30,
ViP-B|384,2021,8.78E+07,Visual Parser: Representing Part-whole Hierarchies with Transformers,/paper/visual-parser-representing-part-whole,https://arxiv.org/pdf/2107.05790v1.pdf,3.91E+10,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.50E+19,,19.65362924,,1.8E+20,,,84.20,
Assemble-ResNet152,2020,,Compounding the Performance Improvements of Assembled Techniques in a Convolutional Neural Network,/paper/compounding-the-performance-improvements-of,https://arxiv.org/abs/2001.06268v2,,,3,,1280000,ImageNet 1K,,,,Tesla P40,8,1.18E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84.20,
Conformer-B,2021,,Conformer: Local Features Coupling Global Representations for Visual Recognition,/paper/conformer-local-features-coupling-global,https://arxiv.org/abs/2105.03889v1,,2.33E+10,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,1,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.37E+19,,19.7298384,,2.1E+20,,,84.10,
FBNetV5-F-CLS,2021,,FBNetV5: Neural Architecture Search for Multiple Tasks in One Run,/paper/fbnetv5-neural-architecture-search-for,https://arxiv.org/pdf/2111.10007v1.pdf,2.10E+09,,3,1100,1280000,ImageNet 1K,60 hours,2.16E+05,,Tesla V100 PCIe 32 GB,64,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.87E+18,2.0E+20,18.9479432,20.29077589,2.0E+20,,,84.10,
PiT-B,2021,7.38E+07,Rethinking Spatial Dimensions of Vision Transformers,/paper/rethinking-spatial-dimensions-of-vision,https://arxiv.org/abs/2103.16302v1,1.25E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.44E+19,,19.15836249,,6.7E+19,,,84.00,
AmoebaNet-A,2018,4.69E+08,Regularized Evolution for Image Classifier Architecture Search,/paper/regularized-evolution-for-image-classifier,https://arxiv.org/abs/1802.01548,,1.04E+11,3,600,1280000,ImageNet 1K,7 days,6.05E+05,,Tesla P100 PCIe 16 GB,100,9.53E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.79E+20,5.8E+20,20.68054581,20.76052236,5.8E+20,,,83.90,96.6
DynamicViT-LV-M/0.8,2021,5.71E+07,DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification,/paper/dynamicvit-efficient-vision-transformers-with,https://arxiv.org/abs/2106.02034v1,9.60E+09,,3,30,1280000,ImageNet 1K,,,,GeForce GTX 1080 Ti,8,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.11E+18,,18.04372371,,7.2E+18,,,83.90,
ECA-ResNet-269-D (A2),2021,,ResNet strikes back: An improved training procedure in timm,,https://arxiv.org/pdf/2110.00476v1.pdf,,,3,,1280000,ImageNet 1K,54 hrs,1.94E+05,,Tesla V100 PCIe 32 GB,32,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.8E+19,,19.9439884,8.8E+19,,,83.90,
Transformer local-attention (NesT-B),2021,6.80E+07,Aggregating Nested Transformers,/paper/aggregating-nested-transformers,https://arxiv.org/abs/2105.12723v2,1.79E+10,,3,300,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.06E+19,,19.31430551,,9.2E+19,,,83.80,
PVTv2-B5,2021,8.20E+07,PVTv2: Improved Baselines with Pyramid Vision Transformer,/paper/pvtv2-improved-baselines-with-pyramid-vision,https://arxiv.org/pdf/2106.13797v4.pdf,1.18E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.36E+19,,19.13333449,,6.4E+19,,,83.80,
Twins-SVT-L,2021,9.92E+07,Twins: Revisiting the Design of Spatial Attention in Vision Transformers,/paper/twins-revisiting-spatial-attention-design-in,https://arxiv.org/abs/2104.13840v3,1.51E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.74E+19,,19.24042943,,8.0E+19,,,83.70,
ViTAE-B-Stage,2021,4.85E+07,ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias,/paper/vitae-vision-transformer-advanced-by,https://arxiv.org/pdf/2106.03348v2.pdf,,1.38E+10,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.18E+19,,19.50236156,,1.3E+20,,,83.60,
"SE-ResNeXt-101, 64x4d, S=2 (320px)",2021,9.80E+07,Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training,/paper/splitnet-divide-and-co-training,https://arxiv.org/abs/2011.14660v3,3.82E+10,,3,350,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.13E+19,,19.71046263,,2.0E+20,,,83.60,96.69
ResT-Large,2021,5.16E+07,ResT: An Efficient Transformer for Visual Recognition,/paper/rest-an-efficient-transformer-for-visual,https://arxiv.org/abs/2105.13677v3,7.90E+09,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.10E+18,,18.95907957,,4.5E+19,,,83.60,96.3
MultiGrain PNASNet (500px),2019,,MultiGrain: a unified image embedding for classes and instances,/paper/multigrain-a-unified-image-embedding-for,https://arxiv.org/pdf/1902.05509v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,83.60,96.7
CycleMLP-B,2021,7.60E+07,CycleMLP: A MLP-like Architecture for Dense Prediction,/paper/cyclemlp-a-mlp-like-architecture-for-dense,https://arxiv.org/abs/2107.10224,1.52E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.75E+19,,19.24329607,,8.0E+19,,,83.40,
sMLPNet-B (ImageNet-1k),2021,6.59E+07,Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?,/paper/sparse-mlp-for-image-recognition-is-self,https://arxiv.org/pdf/2109.05422v1.pdf,1.40E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.61E+19,,19.20758051,,7.4E+19,,,83.40,
T2T-ViT-14|384,2021,2.15E+07,Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet,/paper/tokens-to-token-vit-training-vision,https://arxiv.org/abs/2101.11986v2,,1.71E+10,3,310,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.07E+19,,19.60971902,,1.7E+20,,,83.30,
CeiT-S (384 finetune res),2021,2.42E+07,Incorporating Convolution Designs into Visual Transformers,/paper/incorporating-convolution-designs-into-visual,https://arxiv.org/abs/2103.11816v2,1.29E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.49E+19,,19.17204219,,6.9E+19,,,83.30,96.5
VisformerV2-S,2021,2.36E+07,Visformer: The Vision-friendly Transformer,/paper/visformer-the-vision-friendly-transformer,https://arxiv.org/pdf/2104.12533.pdf,4.30E+09,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.95E+18,,18.69492093,,2.7E+19,,,83.00,
PNASNet-5,2018,8.61E+07,Progressive Neural Architecture Search,/paper/progressive-neural-architecture-search,https://arxiv.org/abs/1712.00559,,2.50E+10,3,,1280000,ImageNet 1K,,,,Tesla P100 PCIe 16 GB,100,9.53E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.90,96.2
Oct-ResNet-152 (SE),2019,6.68E+07,Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution,/paper/drop-an-octave-reducing-spatial-redundancy-in,https://arxiv.org/abs/1904.05049,2.22E+10,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.90,96.3
GFNet-H-B,2021,5.40E+07,Global Filter Networks for Image Classification,/paper/global-filter-networks-for-image,https://arxiv.org/abs/2107.00645v1,8.60E+09,,3,300,1280000,ImageNet 1K,,,,GeForce RTX 3090,8,3.56E+04,,,,,,,,,,,,,,,,,,,,,,30,1280000,ImageNet 1K,,,,,,,,,,,,,1.09E+19,,19.03734362,,5.3E+19,,,82.90,96.2
TNT-B,2021,6.56E+07,Transformer in Transformer,/paper/transformer-in-transformer,https://arxiv.org/abs/2103.00112v2,1.41E+10,,3,253,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.37E+19,,19.13667086,,6.5E+19,"14.1GFLOPS , 253 epochs (https://github.com/huawei-noah/CV, Backbones/blob/master/tnt_pytorch/train.py), 1.28M examples",,82.90,
"Harm-SE-RNX-101 64x4d (320x320, Mean-Max Pooling)",2021,8.82E+07,Harmonic Convolutional Networks based on Discrete Cosine Transform,/paper/harmonic-convolutional-networks-based-on,https://arxiv.org/abs/2001.06570v2,3.14E+10,,3,100,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.21E+19,,19.08126087,,5.8E+19,,,82.85,96.44
CrossViT-18+,2021,4.43E+07,CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification,/paper/2103-14899,https://arxiv.org/pdf/2103.14899.pdf,9.50E+09,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,32,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.09E+19,,19.03917608,,5.3E+19,,,82.80,
FunMatch - T384+224 (ResNet-50),2021,,Knowledge distillation: A good teacher is patient and consistent,/paper/knowledge-distillation-a-good-teacher-is,https://arxiv.org/abs/2106.05237v1,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.80,
	CCT-14/7x2 | 384,2021,2.25E+07,Escaping the Big Data Paradigm with Compact Transformers,/paper/escaping-the-big-data-paradigm-with-compact,https://arxiv.org/pdf/2104.05704v3.pdf,,,3,,1280000,ImageNet 1K,,,,RTX A6000,8,4.00E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.71,
NASNET-A(6),2018,8.89E+07,Learning Transferable Architectures for Scalable Image Recognition,/paper/learning-transferable-architectures-for,https://arxiv.org/abs/1707.07012,,2.38E+10,3,,1280000,ImageNet 1K,4 days,3.46E+05,,Tesla P100 PCIe 16 GB,500,9.53E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.6E+21,,21.21645432,1.6E+21,,,82.70,96.2
Container,2021,2.21E+07,Container: Context Aggregation Network,/paper/container-context-aggregation-network,https://arxiv.org/pdf/2106.01401v2.pdf,8.10E+09,,3,200,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.22E+18,,18.79384624,,3.2E+19,,,82.70,
RVT-B*,2021,9.18E+07,Towards Robust Vision Transformer,/paper/rethinking-the-design-principles-of-robust,https://arxiv.org/abs/2105.07926v3,1.77E+10,,3,,1280000,ImageNet 1K,,,,GeForce RTX 2080 Ti,,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.60,96
LeViT-384,2021,3.91E+07,LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference,/paper/levit-a-vision-transformer-in-convnet-s,https://arxiv.org/abs/2104.01136v2,2.35E+09,,3,1000,1280000,ImageNet 1K,5 days,4.32E+05,,Tesla V100 PCIe 16 GB,32,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.02E+18,2.0E+20,18.95539909,20.29077589,2.0E+20,,,82.60,
BossNet-T1+,2021,,BossNAS: Exploring Hybrid CNN-transformers with Block-wisely Self-supervised Neural Architecture Search,/paper/bossnas-exploring-hybrid-cnn-transformers,https://arxiv.org/abs/2103.12424v2,,1.05E+10,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.50,96
ConViT-B+,2021,1.52E+08,ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases,/paper/convit-improving-vision-transformers-with,https://arxiv.org/abs/2103.10697v2,3.00E+10,,3,300,1280000,ImageNet 1K,,,,Quadro GP100,8,1.03E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.46E+19,,19.53857373,,1.4E+20,,,82.50,95.9
DeiT-B with iRPE-K,2021,8.70E+07,Rethinking and Improving Relative Position Encoding for Vision Transformer,/paper/rethinking-and-improving-relative-position,https://arxiv.org/pdf/2107.14222v1.pdf,,1.77E+10,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.08E+19,,19.61045574,,1.7E+20,,,82.40,
AutoFormer-base,2021,5.40E+07,AutoFormer: Searching Transformers for Visual Recognition,/paper/autoformer-searching-transformers-for-visual,https://arxiv.org/pdf/2107.00651v1.pdf,1.10E+10,,3,300,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,,1.41E+04,,,,,,,,,,,,,,,,,,,,,,40,1280000,ImageNet 1K,,,,,,,,,,,,,1.44E+19,,19.15720283,,6.7E+19,,,82.40,95.7
	ColorNet,2019,5.40E+07,ColorNet: Investigating the importance of color spaces for image classification,/paper/colornet-investigating-the-importance-of,https://arxiv.org/pdf/1902.00267v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.35,94.78
GLiT-Bases,2021,9.61E+07,GLiT: Neural Architecture Search for Global and Local Image Transformer,/paper/glit-neural-architecture-search-for-global,https://arxiv.org/pdf/2107.02960v3.pdf,1.70E+10,,3,100,1280000,ImageNet 1K,,,,GeForce GTX 1080 Ti,,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.53E+18,,18.81478015,,3.4E+19,,,82.30,
Evo-LeViT-384*,2021,,Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer,/paper/evo-vit-slow-fast-token-evolution-for-dynamic,https://arxiv.org/pdf/2108.01390v4.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.20,
DIFFQ (λ=1e−2),2021,,Differentiable Model Compression via Pseudo Quantization Noise,/paper/differentiable-model-compression-via-pseudo,https://arxiv.org/abs/2104.09987,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,82.00,
DVT (T2T-ViT-19),2021,,Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length,/paper/not-all-images-are-worth-16x16-words-dynamic,https://arxiv.org/abs/2105.15075v1,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.93,
AOGNet-40M-AN,2019,4.04E+07,Attentive Normalization,/paper/attentive-normalization,https://arxiv.org/pdf/1908.01259v3.pdf,7.51E+09,,3,200,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.77E+18,,18.76100116,,3.0E+19,,,81.87,95.74
ResNet-200,2021,,Parametric Contrastive Learning,/paper/parametric-contrastive-learning,https://arxiv.org/pdf/2107.12028v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.80,
ResNet-50 + MEAL V2,2021,2.56E+07,MEAL V2: Boosting Vanilla ResNet-50 to 80+ Top-1 Accuracy on ImageNet without Tricks,/paper/meal-v2-boosting-vanilla-resnet-50-to-80-top,https://arxiv.org/abs/2009.08453v2,,,3,,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.72,95.81
T2T-ViT-14,2021,2.15E+07,Beyond Self-attention: External Attention using Two Linear Layers for Visual Tasks,/paper/beyond-self-attention-external-attention,https://arxiv.org/abs/2105.02358v2,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.70,
gMLP-B,2021,7.30E+07,Pay Attention to MLPs,/paper/pay-attention-to-mlps,https://arxiv.org/abs/2105.08050v2,,1.58E+10,3,300,1280000,ImageNet 1K,,,,,,,Cloud TPU v2,16,1.80E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.64E+19,,19.56113956,,1.5E+20,,,81.60,
RandWire-WS,2019,6.15E+07,Exploring Randomly Wired Neural Networks for Image Recognition,/paper/exploring-randomly-wired-neural-networks-for,https://arxiv.org/pdf/1904.01569v2.pdf,1.60E+10,,3,100,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.14E+18,,18.78845121,,3.2E+19,,,81.60,95.4
SKNet-101,2019,4.89E+07,Selective Kernel Networks,/paper/selective-kernel-networks,https://arxiv.org/pdf/1903.06586v2.pdf,8.46E+09,,3,100,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.25E+18,,18.51170159,,1.8E+19,,,81.60,
CoE-Large 214 MFLOPs,2021,,Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs,/paper/collaboration-of-experts-achieving-80-top-1,https://arxiv.org/pdf/2107.03815v1.pdf,2.14E+08,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.50,
PyConvResNet-101,2020,4.23E+07,Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition,/paper/pyramidal-convolution-rethinking,https://arxiv.org/abs/2006.11538v1,1.49E+10,,3,90,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.15E+18,,18.71176,,2.8E+19,,,81.49,95.72
DPN-131 (320x320) With Mean-Max Pooling,2017,7.95E+07,Dual Path Networks,/paper/dual-path-networks,https://arxiv.org/abs/1707.01629,1.60E+10,,3,,1280000,ImageNet 1K,,,,Tesla K80,40,5.60E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.45,95.84
ResNet-200 (Supervised Contrastive),2020,,Supervised Contrastive Learning,/paper/supervised-contrastive-learning,http://proceedings.neurips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.40,95.9
ResNet-200 (Adversarial Autoaugment),2019,,Adversarial AutoAugment,/paper/adversarial-autoaugment-1,https://arxiv.org/pdf/1912.11188v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.32,95.3
Very Deep PolyNet,2017,,PolyNet: A Pursuit of Structural Diversity in Very Deep Networks,/paper/polynet-a-pursuit-of-structural-diversity-in,https://arxiv.org/abs/1611.05725,,,3,,1280000,ImageNet 1K,,,,GeForce Titan X,8,1.10E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.29,95.75
Res2Net-101,2019,,Res2Net: A New Multi-scale Backbone Architecture,/paper/res2net-a-new-multi-scale-backbone,https://arxiv.org/pdf/1904.01169v3.pdf,,,3,,1280000,ImageNet 1K,,,,GeForce Titan Xp,4,1.14E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.23,94.43
ResNeXt-101 (Debiased+CutMix),2020,,Shape-Texture Debiased Neural Network Training,/paper/shape-texture-debiased-neural-network-1,https://openreview.net/forum?id=Db4yerZTYkz,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.20,
ResNet-152x2-SAM,2021,2.36E+08,When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations,/paper/when-vision-transformers-outperform-resnets,https://arxiv.org/abs/2106.01548v1,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,16,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,81.10,
RegNetY-32GF,2020,1.45E+08,Designing Network Design Spaces,/paper/designing-network-design-spaces,http://openaccess.thecvf.com/content_CVPR_2020/html/Radosavovic_Designing_Network_Design_Spaces_CVPR_2020_paper.html,3.23E+10,,3,100,1280000,ImageNet 1K,76 hours,2.74E+05,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.24E+19,3.1E+19,19.09353375,19.49034824,3.1E+19,,,81.00,
ResMLP-B24,2021,1.29E+08,ResMLP: Feedforward networks for image classification with data-efficient training,/paper/resmlp-feedforward-networks-for-image,https://arxiv.org/abs/2105.03404v2,2.30E+10,,3,400,1280000,ImageNet 1K,2 days,1.73E+05,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.53E+19,2.0E+19,19.54811905,19.29077589,2.0E+19,,,81.00,
ResNeXt-101 64x4,2017,8.36E+07,Aggregated Residual Transformations for Deep Neural Networks,/paper/aggregated-residual-transformations-for-deep,https://arxiv.org/abs/1611.05431,,,3,,1280000,ImageNet 1K,10 days,8.64E+05,,Tesla M40,8,6.84E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.7E+19,,19.67491373,4.7E+19,,,80.90,95.6
"CentroidViT-S (arXiv, 2021-02)",2021,2.23E+07,Centroid Transformers: Learning to Abstract with Attention,/paper/centroid-transformers-learning-to-abstract,https://arxiv.org/abs/2102.08606v2,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.90,
LocalViT-S,2021,2.24E+07,LocalViT: Bringing Locality to Vision Transformers,/paper/localvit-bringing-locality-to-vision,https://arxiv.org/abs/2104.05707v1,4.60E+09,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.30E+18,,18.72421031,,2.8E+19,,,80.80,95.4
ResNet-200 (Fast AA),2019,,Fast AutoAugment,/paper/fast-autoaugment,https://arxiv.org/pdf/1905.00397v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.60,95.3
ResNeXt-101 (CutMix),2019,,CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features,/paper/cutmix-regularization-strategy-to-train,https://arxiv.org/abs/1905.04899,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.53,94.97
RepVGG-B3,2021,1.11E+08,RepVGG: Making VGG-style ConvNets Great Again,/paper/repvgg-making-vgg-style-convnets-great-again,http://openaccess.thecvf.com//content/CVPR2021/html/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.html,2.62E+10,,3,200,1280000,ImageNet 1K,,,,GeForce GTX 1080 Ti,8,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.01E+19,,19.30366251,,9.0E+19,,,80.52,
NAT-M4,2020,9.10E+06,Neural Architecture Transfer,/paper/neural-architecture-transfer,https://arxiv.org/abs/2005.05859v2,,6.00E+08,3,,1280000,ImageNet 1K,1 day,8.64E+04,,GeForce RTX 2080 Ti,8,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.3E+18,,18.96822913,9.3E+18,,,80.50,95.2
Attention-92,2017,5.13E+07,Residual Attention Network for Image Classification,/paper/residual-attention-network-for-image,https://arxiv.org/pdf/1704.06904v1.pdf,1.04E+10,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.50,95.2
HCGNet-C,2019,4.22E+07,Gated Convolutional Networks with Hybrid Connectivity for Image Classification,/paper/gated-convolutional-networks-with-hybrid,https://arxiv.org/pdf/1908.09699v3.pdf,7.10E+09,,3,630,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.72E+19,,19.23493012,,7.9E+19,,,80.50,95.2
ResNet-50+AutoDropout+RandAugment,2021,,AutoDropout: Learning Dropout Patterns to Regularize Deep Networks,/paper/autodropout-learning-dropout-patterns-to,https://arxiv.org/abs/2101.01761v1,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v2,1,1.80E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.30,
        Inception ResNet V2 (SENet),2019,,Squeeze-and-Excitation Networks,/paper/squeeze-and-excitation-networks,https://arxiv.org/abs/1709.01507,1.18E+10,,3,100,1280000,ImageNet 1K,,,,GeForce Titan X,8,1.10E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.53E+18,,18.65621323,,2.5E+19,,,80.20,95.21
ConvMLP-L,2021,4.27E+07,ConvMLP: Hierarchical Convolutional MLPs for Vision,/paper/convmlp-hierarchical-convolutional-mlps-for,https://arxiv.org/pdf/2109.04454v2.pdf,,,3,,1280000,ImageNet 1K,,,,RTX A6000,8,4.00E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.20,
WideNet-H,2021,6.30E+07,Go Wider Instead of Deeper,/paper/go-wider-instead-of-deeper,https://arxiv.org/pdf/2107.11817v3.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,Cloud TPU v3,32,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,80.10,
Inception ResNet V2,2016,,"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",/paper/learning-transferable-architectures-for,https://arxiv.org/abs/1707.07012,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,80.10,95.1
ResNet-200,2016,,Identity Mappings in Deep Residual Networks,/paper/identity-mappings-in-deep-residual-networks,https://arxiv.org/pdf/1603.05027v3.pdf,,,3,,1280000,ImageNet 1K,3 weeks,1.81E+06,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.90,95.2
Modified Aligned Xception,2018,,Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation,/paper/encoder-decoder-with-atrous-separable,https://arxiv.org/pdf/1802.02611v3.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.81,94.83
iAFF-ResNeXt-50-32x4d,2020,3.47E+07,Attentional Feature Fusion,/paper/attentional-feature-fusion,https://arxiv.org/abs/2009.14082v2,4.30E+09,,3,160,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.64E+18,,18.42191966,,1.5E+19,,,79.80,94.9
CSPResNeXt-50 + Mish,2019,,Mish: A Self Regularized Non-Monotonic Activation Function,/paper/mish-a-self-regularized-non-monotonic-neural,https://arxiv.org/pdf/1908.08681v3.pdf,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.80,95.2
Grafit (ResNet-50),2020,,Grafit: Learning fine-grained image representations with coarse labels,/paper/grafit-learning-fine-grained-image,https://arxiv.org/abs/2011.12982v1,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.60,
TinyNet (GhostNet),2020,1.19E+07,"Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets",/paper/model-rubik-s-cube-twisting-resolution-depth,https://arxiv.org/abs/2010.14819v2,5.91E+08,,3,450,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.02E+18,,18.00913122,,6.7E+18,,,79.40,94.5
ScaleNet-152,2019,,Data-Driven Neuron Allocation for Scale Aggregation Networks,/paper/190409460,https://arxiv.org/pdf/1904.09460v1.pdf,1.12E+10,,3,100,1280000,ImageNet 1K,,,,GeForce GTX 1060,8,4.38E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.30E+18,,18.63354925,,2.4E+19,,,79.38,94.66
LIP-ResNet-101,2019,4.29E+07,LIP: Local Importance-based Pooling,/paper/lip-local-importance-based-pooling,https://arxiv.org/pdf/1908.04156v3.pdf,9.06E+09,,3,,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.33,94.6
RedNet-152,2021,3.40E+07,Involution: Inverting the Inherence of Convolution for Visual Recognition,/paper/involution-inverting-the-inherence-of,http://openaccess.thecvf.com//content/CVPR2021/html/Li_Involution_Inverting_the_Inherence_of_Convolution_for_Visual_Recognition_CVPR_2021_paper.html,6.80E+09,,3,130,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,64,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.39E+18,,18.53078349,,1.9E+19,,,79.30,
ResNet-50 + tricks,2018,2.50E+07,Bag of Tricks for Image Classification with Convolutional Neural Networks,/paper/bag-of-tricks-for-image-classification-with,https://arxiv.org/pdf/1812.01187v2.pdf,4.30E+09,,3,120,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.98E+18,,18.29698093,,1.2E+19,,,79.29,94.63
PS-KD (ResNet-152 + CutMix),2020,,Self-Knowledge Distillation with Progressive Refinement of Targets,/paper/self-knowledge-distillation-a-simple-way-for,https://arxiv.org/pdf/2006.12000v3.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.24,94.66
Multiscale DEQ (MDEQ-XL),2020,8.10E+07,Multiscale Deep Equilibrium Models,/paper/multiscale-deep-equilibrium-models,http://proceedings.neurips.cc/paper/2020/hash/3812f9a59b634c2a9c574610eaba5bed-Abstract.html,,,3,,1280000,ImageNet 1K,,,,Quadro RTX 8000,8,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.20,94.5
ResNet-101 (JFT-300M Finetuning),2017,,Revisiting Unreasonable Effectiveness of Data in Deep Learning Era,/paper/revisiting-unreasonable-effectiveness-of-data,https://arxiv.org/pdf/1707.02968v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.20,94.7
DenseNet-264,2016,,Densely Connected Convolutional Networks,/paper/densely-connected-convolutional-networks,https://arxiv.org/pdf/1608.06993v5.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.20,94.71
AA-ResNet-152,2019,6.16E+07,Attention Augmented Convolutional Networks,/paper/190409925,https://arxiv.org/pdf/1904.09925v5.pdf,2.38E+10,,3,100,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.14E+18,,18.96090818,,4.5E+19,,,79.10,94.6
ResNet-50 (UDA),2019,,Unsupervised Data Augmentation for Consistency Training,/paper/unsupervised-data-augmentation-1,https://arxiv.org/pdf/1904.12848v6.pdf,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,16,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.05,94.49
Xception,2017,2.29E+07,Xception: Deep Learning with Depthwise Separable Convolutions,/paper/xception-deep-learning-with-depthwise,https://arxiv.org/pdf/1610.02357v3.pdf,,8.38E+09,3,,1280000,ImageNet 1K,3 days,2.59E+05,,Tesla K80,60,5.60E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.7E+19,,19.93997427,8.7E+19,,,79.00,94.5
SpineNet-143,2019,6.05E+07,SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization,/paper/spinenet-learning-scale-permuted-backbone-for,https://arxiv.org/pdf/1912.05027v3.pdf,9.10E+09,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79.00,94.4
InceptionV3 (FRN layer),2019,,Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks,/paper/filter-response-normalization-layer,https://arxiv.org/pdf/1911.09737v2.pdf,,,3,,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.95,94.49
ResNet-152 + SWA,2018,,Averaging Weights Leads to Wider Optima and Better Generalization,/paper/averaging-weights-leads-to-wider-optima-and,https://arxiv.org/pdf/1803.05407v3.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.94,
ECA-Net (ResNet-152),2019,5.74E+07,ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks,/paper/eca-net-efficient-channel-attention-for-deep,https://arxiv.org/pdf/1910.03151v4.pdf,1.08E+10,,3,100,1280000,ImageNet 1K,,,,GeForce RTX 2080 Ti,4,1.34E+04,,,,Intel Silver 4112,1,332.8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.15E+18,,18.61775498,,2.3E+19,,,78.92,94.55
MixNet-L,2019,7.30E+06,MixConv: Mixed Depthwise Convolutional Kernels,/paper/mixnet-mixed-depthwise-convolutional-kernels,https://arxiv.org/pdf/1907.09595v3.pdf,5.65E+08,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.90,94.2
Inception V3,2018,2.38E+07,Rethinking the Inception Architecture for Computer Vision,/paper/learning-transferable-architectures-for,https://arxiv.org/abs/1707.07012,4.80E+09,,3,100,1280000,ImageNet 1K,,,,Tesla K80,50,5.60E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.84E+18,,18.26557246,,1.1E+19,,,78.80,94.4
SGE-ResNet101,2019,4.46E+07,Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks,/paper/spatial-group-wise-enhance-improving-semantic,https://arxiv.org/pdf/1905.09646v2.pdf,7.86E+09,,3,100,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.02E+18,,18.47975377,,1.7E+19,,,78.80,94.368
ResNet-50,2020,,Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup,/paper/puzzle-mix-exploiting-saliency-and-local-1,https://proceedings.icml.cc/static/paper_files/icml/2020/6618-Paper.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.76,94.29
RepMLP-Res50,2021,5.28E+07,RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition,/paper/repmlp-re-parameterizing-convolutions-into,https://arxiv.org/abs/2105.01883v1,,,3,,1280000,ImageNet 1K,,,,GeForce GTX 1080 Ti,8,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.60,
ResNet-152,2015,,Deep Residual Learning for Image Recognition,/paper/deep-residual-learning-for-image-recognition,https://arxiv.org/pdf/1512.03385.pdf,,1.13E+10,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.57,94.29
ResNet-50-DW (Deformable Kernels),2019,,Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation,/paper/deformable-kernels-adapting-effective,https://arxiv.org/pdf/1910.02940v2.pdf,4.60E+09,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.50,
SRM-ResNet-101,2019,4.47E+07,SRM : A Style-based Recalibration Module for Convolutional Neural Networks,/paper/srm-a-style-based-recalibration-module-for,https://arxiv.org/pdf/1903.10829v1.pdf,7.62E+09,,3,90,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.63E+18,,18.42052871,,1.5E+19,,,78.47,94.2
MobileViT,2021,,"MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer",/paper/mobilevit-light-weight-general-purpose-and,https://arxiv.org/pdf/2110.02178v1.pdf,,,3,300,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.40,
"ResNet-50 + DropBlock (0.9 kp, 0.1 label smoothing)",2018,,DropBlock: A regularization method for convolutional networks,/paper/dropblock-a-regularization-method-for,https://arxiv.org/abs/1810.12890,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.35,94.15
ResNet-152,2017,,IDK Cascades: Fast Deep Learning by Learning not to Overthink,/paper/idk-cascades-fast-deep-learning-by-learning,https://arxiv.org/abs/1706.00885,,1.13E+10,3,100,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.68E+18,,18.93843966,,4.3E+19,,,78.30,
EfficientNet-B0 (CondConv),2019,,CondConv: Conditionally Parameterized Convolutions for Efficient Inference,/paper/soft-conditional-computation,https://arxiv.org/pdf/1904.04971v3.pdf,,4.13E+08,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.30,
CSPResNeXt-50 (10 crop),2019,2.05E+07,CSPNet: A New Backbone that can Enhance Learning Capability of CNN,/paper/cspnet-a-new-backbone-that-can-enhance,https://arxiv.org/pdf/1911.11929v1.pdf,7.90E+10,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.20,94.3
WRN-50-2-bottleneck,2017,6.89E+07,Wide Residual Networks,/paper/wide-residual-networks,https://arxiv.org/pdf/1605.07146v4.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,78.10,93.97
Perceiver (FF),2021,4.49E+07,Perceiver: General Perception with Iterative Attention,/paper/perceiver-general-perception-with-iterative,https://arxiv.org/abs/2103.03206v2,7.07E+11,,3,120,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,64,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.26E+20,,20.51293188,,1.0E+21,,,78.00,
HVT-S-1,2021,2.17E+07,Scalable Visual Transformers with Hierarchical Pooling,/paper/scalable-visual-transformers-with,https://arxiv.org/abs/2103.10619v1,2.40E+09,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.76E+18,,18.44166372,,1.6E+19,,,78.00,93.83
ACNet (ResNet-50),2019,2.94E+07,Adaptively Connected Neural Networks,/paper/adaptively-connected-neural-networks,https://arxiv.org/pdf/1904.03579v1.pdf,,,3,,1280000,ImageNet 1K,,,,GeForce Titan Xp,8,1.14E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.50,
Prodpoly,2020,,Deep Polynomial Neural Networks,/paper/deep-polynomial-neural-networks,https://arxiv.org/abs/2006.13026v2,,,3,90,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,4,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.17,93.569
Inception v3,2018,,What do Deep Networks Like to See?,/paper/what-do-deep-networks-like-to-see,https://arxiv.org/pdf/1803.08337v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.12,93.25
GreedyNAS-A,2020,6.50E+06,GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet,/paper/greedynas-towards-fast-one-shot-nas-with,http://openaccess.thecvf.com/content_CVPR_2020/html/You_GreedyNAS_Towards_Fast_One-Shot_NAS_With_Greedy_Supernet_CVPR_2020_paper.html,3.66E+08,,3,,1280000,ImageNet 1K,7 gpu days,6.05E+05,,Tesla V100 PCIe 32 GB,1,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.5E+18,,18.93175394,8.5E+18,,,77.10,93.3
SkipblockNet-L,2021,7.10E+06,Bias Loss for Mobile Neural Networks,/paper/bias-loss-for-mobile-neural-networks,https://arxiv.org/pdf/2107.11170v3.pdf,3.64E+08,,3,,1280000,ImageNet 1K,,,,GeForce RTX 2080 Ti,2,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.10,93.4
SSAL-Resnet50,2021,,Contextual Classification Using Self-Supervised Auxiliary Models for Deep Neural Networks,/paper/contextual-classification-using-self,https://arxiv.org/abs/2101.03057v1,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,77.00,93.8
SCARLET-A,2020,6.70E+06,SCARLETNAS: Bridging the Gap between Stability and Scalability in Weightsharing Neural Architecture Search,/paper/scarletnas-bridging-the-gap-between,https://arxiv.org/pdf/1908.06022v5.pdf,,3.65E+08,3,,1280000,ImageNet 1K,10 GPU days,8.64E+05,,Tesla V100 PCIe 32 GB,1,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.2E+19,,19.0866559,1.2E+19,,,76.90,93.4
"Perona Malik (Perona and Malik, 1990)",2020,,Learning Visual Representations for Transfer Learning by Suppressing Texture,/paper/learning-visual-representations-for-transfer-1,https://arxiv.org/abs/2011.01901v2,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,3 days,2.59E+05,,GeForce GTX 1080 Ti,4,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,1.2E+19,,19.07029655,1.2E+19,,,76.71,
MnasNet-A3,2019,5.20E+06,MnasNet: PlatformAware Neural Architecture Search for Mobile,/paper/mnasnet-platform-aware-neural-architecture,https://arxiv.org/pdf/1807.11626v3.pdf,,4.03E+08,3,,1280000,ImageNet 1K,4.5 days,3.89E+05,,,,,Cloud TPU v2,64,1.80E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.5E+21,,21.65117874,4.5E+21,,,76.70,93.3
MUXNet-l,2020,4.00E+06,MUXConv: Information Multiplexing in Convolutional Neural Networks,/paper/muxconv-information-multiplexing-in,http://openaccess.thecvf.com/content_CVPR_2020/html/Lu_MUXConv_Information_Multiplexing_in_Convolutional_Neural_Networks_CVPR_2020_paper.html,,3.18E+08,3,,1280000,ImageNet 1K,11 days,9.50E+05,,GeForce RTX 2080 Ti,16,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0E+20,,20.31065182,2.0E+20,,,76.60,93.2
"ResNet-50 (X-volution, stage3)",2021,,X-volution: On the unification of convolution and self-attention,/paper/x-volution-on-the-unification-of-convolution,https://arxiv.org/abs/2106.02253v2,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76.60,93.3
VGG-19,2015,,Very Deep Convolutional Networks for Large-Scale Image Recognition,/paper/very-deep-convolutional-networks-for-large,https://arxiv.org/pdf/1409.1556v6.pdf,,,3,,1280000,ImageNet 1K,3 weeks,1.81E+06,,GeForce GTX Titan Black,4,5.12E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.7E+19,,19.57011388,3.7E+19,,,76.30,93.2
LR-Net-26-NL,2019,3.71E+07,Local Relation Networks for Image Recognition,/paper/190411491,https://arxiv.org/pdf/1904.11491v1.pdf,5.60E+09,,3,110,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.37E+18,,18.37391194,,1.4E+19,,,76.00,92.8
ResNet-50 MLPerf v0.7 - 2512 steps,2021,,"A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes",/paper/a-large-batch-optimizer-reality-check,https://arxiv.org/abs/2102.06356v3,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.92,
MoGA-A,2020,5.10E+06,Searching Beyond MobileNetV3,/paper/moga-searching-beyond-mobilenetv3,https://arxiv.org/pdf/1908.01314v4.pdf,,3.04E+08,3,,1280000,ImageNet 1K,6 days,5.18E+05,,Tesla V100 PCIe 32 GB,2,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.5E+19,,19.16583715,1.5E+19,,,75.90,92.8
FractalNet-34,2016,,FractalNet: Ultra-Deep Neural Networks without Residuals,/paper/fractalnet-ultra-deep-neural-networks-without,https://arxiv.org/pdf/1605.07648v4.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.88,92.61
CoordConv ResNet-50,2018,,An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution,/paper/an-intriguing-failing-of-convolutional-neural,https://arxiv.org/pdf/1807.03247v2.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.74,92.75
PReLUNet-C,2015,,Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,,https://arxiv.org/pdf/1502.01852v1.pdf,,,3,,1280000,ImageNet 1K,4 weeks,2.42E+06,,Tesla K40,8,3.52E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.8E+19,,19.83384079,6.8E+19,,,75.73,92.62
RESNASNet,2019,5.36E+06,RENAS: Reinforced Evolutionary Neural Architecture Search,/paper/dicenet-dimension-wise-convolutions-for,https://arxiv.org/abs/1906.03516,2.98E+08,,3,200,1280000,ImageNet 1K,1.5 days,1.30E+05,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.29E+17,,17.35957748,,1.8E+18,,,75.70,
DiCENet,2019,,DiCENet: Dimension-wise Convolutions for Efficient Networks,,https://arxiv.org/pdf/1808.00193.pdf,,5.80E+08,3,300,1280000,ImageNet 1K,3 days,2.59E+05,,GeForce GTX 1080 Ti,4,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.34E+18,1.2E+19,18.12591047,19.07029655,1.2E+19,,,75.70,92.6
GhostNet,2019,7.30E+06,GhostNet: More Features from Cheap Operations,/paper/ghostnet-more-features-from-cheap-operations,https://arxiv.org/pdf/1911.11907v2.pdf,2.26E+08,,3,,1280000,ImageNet 1K,,,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.70,92.7
AlphaX-1,2019,5.40E+06,AlphaX: eXploring Neural Architectures with Deep Neural Networks and Monte Carlo Tree Search,/paper/alphax-exploring-neural-architectures-with-1,https://arxiv.org/abs/1903.11059,,5.79E+08,3,200,1280000,ImageNet 1K,8 GPU days,6.91E+05,,GeForce GTX 1080 Ti,1,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.89E+17,7.8E+18,17.94906978,18.89420529,7.8E+18,,,75.50,92.2
"PAWS (ResNet-50, 10 labels, 300 epochs)",2021,,Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples,/paper/semi-supervised-learning-of-visual-features,https://arxiv.org/abs/2104.13963v2,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 16 GB,64,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.50,
ShuffleNet V2,2018,,ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design,/paper/shufflenet-v2-practical-guidelines-for,https://arxiv.org/pdf/1807.11164v1.pdf,5.97E+08,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.40,
ShuffleNet,2017,,ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,/paper/shufflenet-an-extremely-efficient,https://arxiv.org/pdf/1707.01083v2.pdf,5.27E+08,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.30,89.8
DenseNAS-A,2020,,Densely Connected Search Space for More Flexible Neural Architecture Search,/paper/densely-connected-search-space-for-more,https://arxiv.org/pdf/1906.09607v3.pdf,3.61E+08,,3,,1280000,ImageNet 1K,64 hours,2.30E+05,,GeForce Titan Xp,1,1.14E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.6E+18,,18.41810541,2.6E+18,,,75.30,
DY-MobileNetV2 ×1.0,2019,1.11E+07,Dynamic Convolution: Attention over Convolution Kernels,/paper/dynamic-convolution-attention-over,https://arxiv.org/pdf/1912.03458v2.pdf,,3.13E+08,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.21E+17,,17.85802681,,5.0E+18,,,75.20,92.1
MobileNet V3-Large 1.0,2019,5.40E+06,Searching for MobileNetV3,/paper/searching-for-mobilenetv3,https://arxiv.org/pdf/1905.02244v5.pdf,,2.19E+08,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,2,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,75.20,
Single-Path NAS,2019,,Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours,/paper/single-path-nas-designing-hardware-efficient,https://arxiv.org/pdf/1904.02877v1.pdf,,,3,,1280000,ImageNet 1K,3.75 hours,1.35E+04,,,,,Cloud TPU v2,1,1.80E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.4E+18,,18.38560627,2.4E+18,,,74.96,92.21
ESPNetv2,2018,5.90E+06,"ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network",/paper/espnetv2-a-light-weight-power-efficient-and,https://arxiv.org/pdf/1811.11431v3.pdf,6.02E+08,,3,300,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.94E+17,,17.84104897,,4.8E+18,,,74.90,
FBNet-C,2018,5.50E+06,FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search,/paper/fbnet-hardware-aware-efficient-convnet-design,https://arxiv.org/pdf/1812.03443v3.pdf,3.75E+08,,3,360,1280000,ImageNet 1K,216 hours,7.78E+05,,,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.18E+17,,17.71466499,,3.7E+18,,,74.90,
FF,2021,,Do You Even Need Attention? A Stack of Feed-Forward Layers Does Surprisingly Well on ImageNet,/paper/do-you-even-need-attention-a-stack-of-feed,https://arxiv.org/abs/2105.02723,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.90,
MobileNetV2 (1.4),2018,,MobileNetV2: Inverted Residuals and Linear Bottlenecks,/paper/mobilenetv2-inverted-residuals-and-linear,https://arxiv.org/pdf/1801.04381v4.pdf,,5.85E+08,3,,1280000,ImageNet 1K,,,,,16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.70,
"TreeCell-B with CondenseNet (G1 = 4, G3 = 8)",2018,,Path-Level Network Transformation for Efficient Architecture Search,/paper/path-level-network-transformation-for,https://arxiv.org/abs/1806.02639,,5.94E+08,3,,1280000,ImageNet 1K,200 hours,7.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74.60,91.9
Proxyless,2018,,ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware,/paper/proxylessnas-direct-neural-architecture,https://arxiv.org/pdf/1812.00332v2.pdf,,,3,,1280000,ImageNet 1K,200 hours,7.20E+05,,Tesla V100 PCIe 32 GB,1,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0E+19,,19.00747466,1.0E+19,,,74.60,92.2
DARTS,2019,4.70E+06,DARTS: Differentiable Architecture Search,/paper/alphax-exploring-neural-architectures-with-1,https://arxiv.org/pdf/1806.09055.pdf,,5.74E+08,3,,1280000,ImageNet 1K,12 days,1.04E+06,,GeForce GTX 1080 Ti,1,1.13E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.2E+19,,19.07029655,1.2E+19,,,73.30,91.3
Wide ResNet-50 (edge-popup),2019,2.06E+07,What's Hidden in a Randomly Weighted Neural Network?,/paper/whats-hidden-in-a-randomly-weighted-neural,https://arxiv.org/pdf/1911.13299v2.pdff,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,73.30,
MobileNet-224 (CGD),2019,,Compact Global Descriptor for Neural Networks,/paper/compact-global-descriptor-for-neural-networks,https://arxiv.org/abs/1907.09665,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72.56,90.92
SPPNet,2015,,Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,/paper/spatial-pyramid-pooling-in-deep-convolutional,https://arxiv.org/pdf/1406.4729v4.pdf,,,3,,1280000,ImageNet 1K,4 weeks,2.42E+06,,GeForce GTX Titan,1,4.50E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.1E+19,,19.03685533,1.1E+19,,,72.14,90.86
ResNet-50,2019,,On the adequacy of untuned warmup for adaptive optimization,/paper/on-the-adequacy-of-untuned-warmup-for,https://arxiv.org/pdf/1910.04209v3.pdf,,,3,,1280000,ImageNet 1K,,,,Tesla V100 PCIe 32 GB,8,1.41E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,72.10,
ResNet-18 (PAD-L2 w/ ResNet-34 teacher),2021,,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",/paper/torchdistill-a-modular-configuration-driven,https://arxiv.org/abs/2011.12913v2,,,3,,1280000,ImageNet 1K,28hrs 34mins,1.03E+05,,GeForce RTX 2080 Ti,3,1.34E+04,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.1E+18,,18.61790873,4.1E+18,,,71.71,
Heteroscedastic (InceptionResNet-v2),2021,,Correlated Input-Dependent Label Noise in Large-Scale Image Classification,/paper/correlated-input-dependent-label-noise-in,https://arxiv.org/pdf/2105.10305.pdf,,,3,,1280000,ImageNet 1K,,,,,,,Cloud TPU v3,2,4.20E+05,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,68.60,87.1
Graph-RISE (40M),2019,,Graph-RISE: Graph-Regularized Image Semantic Embedding,/paper/graph-rise-graph-regularized-image-semantic,https://arxiv.org/pdf/1902.10814v1.pdf,,,3,,1280000,ImageNet 1K,2 weeks,1.21E+06,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,68.29,87.75
ReActNet-A (BN-Free),2021,,"""BNN - BN = ?"": Training Binary Neural Networks without Batch Normalization",/paper/bnn-bn-training-binary-neural-networks,https://arxiv.org/abs/2104.08215v1,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,68.00,
Five Base + Five HiRes,2013,,Some Improvements on Deep Convolutional Neural Network Based Image Classification,/paper/some-improvements-on-deep-convolutional,https://arxiv.org/pdf/1312.5402v1.pdf,,,3,,1280000,ImageNet 1K,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66.30,86.3
OverFeat - 7 accurate models,2013,,"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks",/paper/overfeat-integrated-recognition-localization,https://arxiv.org/pdf/1312.6229v4.pdf,,,3,,1280000,ImageNet 1K,,,,Tesla K20X,2,3.94E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,66.04,86.76
"ZFNet (ensemble, 6 convnets)",2013,,Visualizing and Understanding Convolutional Networks,/paper/visualizing-and-understanding-convolutional,https://arxiv.org/pdf/1311.2901v3.pdf,,,3,70,1280000,ImageNet 1K,12 days,1.04E+06,,GeForce GTX 580,1,1.58E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.6E+18,,18.21465433,1.6E+18,,,64.00,85.3
AlexNet,2012,6.00E+07,ImageNet Classification with Deep Convolutional Neural Networks,/paper/imagenet-classification-with-deep,http://papers.nips.cc/paper/4824imagenetclassificationwithdeepconvolutionalneuralnetworks.pdf,,7.00E+08,3,100,1280000,ImageNet 1K,6 days,5.18E+05,,GeForce GTX 580,2,1.58E+03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.38E+17,1.6E+18,17.73045926,18.21465433,1.6E+18,,,63.30,84.6